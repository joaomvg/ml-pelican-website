<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>"Boltzmann Machine" â€” Data Science and Machine Learning</title>
	<meta name="description" content="Title: "Boltzmann Machine"; Date: 2020-12-20; Author: Joao Gomes">
	<meta name="author" content="Joao Gomes">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
	<!--[if lt IE 9]>
		<script src="/theme/html5.js"></script>
		<![endif]-->
	<link href="/theme/css/ipython.css" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/bootswatch/3.2.0/simplex/bootstrap.min.css" rel="stylesheet">
	<link href="/theme/css/local.css" rel="stylesheet">
	<link href="/theme/css/pygments.css" rel="stylesheet">
</head>
<body>
<div class="container">
	<div class="page-header">
		<h1><a href="/">Data Science and Machine Learning</a>
			<br>	</div>
	<div class="row">
		<div class="col-md-8 col-md-offset-2">
<div class="article" itemscope itemtype="http://schema.org/BlogPosting">
	<div class="text-center article-header">
		<h1 itemprop="name headline" class="article-title">"Boltzmann Machine"</h1>
		<span itemprop="author" itemscope itemtype="http://schema.org/Person">
			<h4 itemprop="name">Joao Gomes</h4>
		</span>
		<time datetime="2020-12-20T00:00:00+01:00" itemprop="datePublished">Sun 20 December 2020</time>
	</div>
	<div>
		Category:
		<span itemprop="articleSection">
			<a href="/category/machine-learning.html" rel="category">Machine Learning</a>
		</span>
	</div>
 
	<div>
		Tags:
		<span itemprop="keywords">
			<a href="/tag/data-science.html" rel="tag">data science</a>
		</span>
	</div>
	<div itemprop="articleBody" class="article-body"><ol>
<li><a href="#bm">Boltzmann machine</a></li>
<li><a href="#train">Training</a></li>
<li><a href="#python">Python implementation</a></li>
</ol>
<p><a name="bm"></a></p>
<h3><strong>1. Boltzmann Machine</strong></h3>
<p>A Boltzmann machine models an unsupervised probability distribution using a graphical representation composed of visible and hidden units. The probability of the visible data is given as a sum of the exponential of an energy term <span class="math">\(E(v,h)\)</span>, much like the Boltzmann distribution in statistical mechanics. For the diagram below 
<img alt="" height="200" src="/images/bm.png" style="display: block; margin: 0 auto" width="200"> </p>
<p>the probability has the form
</p>
<div class="math">$$
P(v)=\sum_{\{h\}}P(v,h)=\sum_{\{h\}}\frac{\exp{E(v,h)}}{Z}=\sum_{\{h\}}\frac{\exp{(-\sum_iv_ia_i-\sum_ih_ib_i-\sum_{i,j}v_iW_{ij}h_j)}}{Z}
$$</div>
<p>
where the sum is over all hidden configurations <span class="math">\(h=\{0,1\}^d\)</span>, with <span class="math">\(d\)</span> the dimension of the hidden layer. The parameters <span class="math">\(a,b\)</span> are the biases and <span class="math">\(W_{ij}\)</span> is a matrix representing the interactions between the visible and hidden layers. The visible unit is composed of binary features <span class="math">\(v_i=\{0,1\}\)</span>. The normalization <span class="math">\(Z\)</span> is the partition function
</p>
<div class="math">$$Z(a,b,W)=\sum_{v,h}P(v,h)$$</div>
<p>The Boltzmann machine can have more complicated graph interaction including edges between both visible and hidden units. For example
<img alt="" height="200" src="/images/bm3.png" style="display: block; margin: 0 auto" width="200"> </p>
<p>A restricted Boltzmann machine is a Boltzmann machine for which there are no interactions between the nodes in the same layer. In terms of parameters, for each node <span class="math">\(i\)</span>, either visible or hidden, we have a bias <span class="math">\(b_i\)</span>, and for each edge between the nodes <span class="math">\(i\)</span> and <span class="math">\(j\)</span> we have a parameter <span class="math">\(W_{ij}\)</span> .</p>
<p><a name="Train"></a></p>
<h3><strong>2. Training</strong></h3>
<p>In training we want to minimize the Kullback-Leibler divergence between the true distribution of visible data <span class="math">\(D(v)\)</span> and the output of the Boltzmann machine <span class="math">\(P(v)\)</span>. That is, we seek the optimum of</p>
<div class="math">$$
KL(D||P)=\sum_v D(v)\ln\Big(\frac{D(v)}{P(v)}\Big)
$$</div>
<p>Lets focus for the moment on a restricted machine with one hidden layer. The derivatives of the loss <span class="math">\(L\equiv KL(D||P)\)</span> function with respect to the weights is
</p>
<div class="math">$$\begin{aligned}
\frac{\partial L}{\partial W_{ij}}&amp;=\sum_v D(v)\frac{\sum_h v_ih_j \exp{E(v,h)}}{\sum_h \exp{E(v,h)}}
-\sum_v D(v)\frac{\sum_{v',h'}v'_ih'_j \exp{E(v',h')}}{Z}\\
&amp;=\sum_{v,h} v_ih_j P(h|v)D(v) -\sum_{v,h}v_ih_j P(v,h)\\
&amp;=\langle v_ih_j\rangle_{data}-\langle v_ih_j\rangle_{model}
\end{aligned}
$$</div>
<p>
and similarly for the biases
</p>
<div class="math">$$\begin{aligned}
&amp;\frac{\partial L}{\partial a_{i}}=\langle v_i\rangle_{data}-\langle v_i\rangle_{model}\\
&amp;\frac{\partial L}{\partial b_{i}}=\langle h_i\rangle_{data}-\langle h_i\rangle_{model}
\end{aligned}
$$</div>
<p>
Since the gradient can be written as the sum of two averages one may try to use stochastic optimization. In order to calculate <span class="math">\(\langle hv\rangle_{data}\)</span> we can generate unbiased samples <span class="math">\(h_iv_j\)</span> and then take the average as an estimate. To do that we can use Gibbs sampling. First we pick a training sample <span class="math">\(v\)</span> and then generate a sample <span class="math">\(h\)</span> using the conditional probability <span class="math">\(P(h_1,h_2,\ldots|v)\)</span>. In fact we can write</p>
<div class="math">$$\begin{aligned}
P(h_1,h_2,\ldots|v)&amp;=\frac{P(h_1,h_2,\ldots,v)}{\sum_h P(h,v)}=\\
&amp;=\frac{\exp{(-\sum_j h_jb_j -\sum_{ij}v_iW_{ij}h_j)}}{\prod_{j}(1+\exp{(-b_j-\sum_{i}v_i W_{ij})})}\\
&amp;=\prod_j\frac{\exp{(-h_jb_j -h_j\sum_{i}v_iW_{ij})}}{(1+\exp{(-b_j-\sum_{i}v_i W_{ij})})}\\
&amp;=\prod_{j=1}^{N_h} P(h_j|v)
\end{aligned}
$$</div>
<p>
where <span class="math">\(N_h\)</span> is the number of hidden units and we have defined
</p>
<div class="math">$$
P(h_j=1|v)=\frac{1}{1+\exp{(b_i+\sum_i v_iW_{ij})}}
$$</div>
<p>
Similarly the probability <span class="math">\(P(v_1,v_2,\ldots|h)\)</span> can be written as
</p>
<div class="math">$$
P(v_1,v_2,\ldots|h)=\prod_{i=1}^{N_v} P(v_i|h)
$$</div>
<p>
where <span class="math">\(N_v\)</span> is the number of visible units and
</p>
<div class="math">$$
P(v_i=1|h)=\frac{1}{1+\exp{(a_i+\sum_j W_{ij}h_j)}}
$$</div>
<p>
The probabilty for visible states can also be written in a compact way. Defining
</p>
<div class="math">$$\begin{aligned}
\Phi(v)&amp;\equiv\sum_{h}\exp{(-\sum_i v_i a_i-\sum_j h_j b_j-\sum_{ij}v_iW_{ij}h_j)}=\\
&amp;=\exp{(-\sum_i v_i a_i)}\prod_{j}(1+\exp{(-b_j-\sum_{i}v_i W_{ij})})
\end{aligned}
$$</div>
<p>
this probability becomes
</p>
<div class="math">$$
P(v)=\frac{\Phi(v)}{\sum_v \Phi(v)}
$$</div>
<p>However, to generate a sample for the average <span class="math">\(\langle hv\rangle_{model}\)</span> is quite harder because we do not have direct access to <span class="math">\(P(v)\)</span>. Instead choose a training vector <span class="math">\(v\)</span> and generate a state <span class="math">\(h\)</span> using <span class="math">\(P(h|v)\)</span>. Further, given this state <span class="math">\(h\)</span> reconstruct the state <span class="math">\(v\)</span> using <span class="math">\(P(v|h)\)</span>. The change in the weight is then given by</p>
<div class="math">$$
\Delta W_{ij}=-\eta( \langle v_ih_j\rangle_{data}-\langle v_ih_j\rangle_{recons})
$$</div>
<p>
where <span class="math">\(\eta\)</span> is the learning rate.</p>
<p>If the Boltzmann machine contains couplings between nodes in the same layer, the analysis is very similar. We calculate the derivatives of the loss with respect to <span class="math">\(L_{ij}\)</span> and <span class="math">\(J_{ij}\)</span>, respectively the couplings between visible-visible and hidden-hidden units,
</p>
<div class="math">$$
\begin{aligned}
&amp;\frac{\partial L}{\partial L_{ij}}=\langle v_iv_j\rangle_{data}-\langle v_iv_j\rangle_{model}\\
&amp;\frac{\partial L}{\partial J_{ij}}=\langle h_ih_j\rangle_{data}-\langle h_ih_j\rangle_{model}
\end{aligned}
$$</div>
<p>
Again the idea is to replace the model average with a point estimate, by generating unbiased samples <span class="math">\(v_iv_j\)</span> and <span class="math">\(h_ih_j\)</span> and calculate their sample averages.</p>
<p>To monitor training we usually plot values of the log-likelihood function. However, in a Boltzmann machine determining the probability <span class="math">\(P(v)\)</span> is prohibitively expensive since calculating the partition function <span class="math">\(Z\)</span> requires adding up an exponential number of terms. The complexity is of order <span class="math">\(\mathcal{O}(2^{N_v})\)</span>, where <span class="math">\(N_v\)</span> is the number of visible units. Instead, we calculate the pseudo-loglikelihood. This quantity is defined as
</p>
<div class="math">$$
\text{Pseudo-LL}(v)=\sum_{i}\ln P(v_i|\{v_{j\neq i}\})
$$</div>
<p>
that is, the sum over the log-probabilities conditioned on the remaining visible units. Remember that the log-likelihood can be written as
</p>
<div class="math">$$
\ln P(v)=\ln P(v_1)+\ln P(v_2|v_1) +\ln P(v_3|v_1,v_2)+\ldots+\ln P(v_n|\{v_{1:n-1}\})
$$</div>
<p>
after using the Bayes theorem. It can be shown that the pseudo-loglikelihood descreases during training.</p>
<p><a name="python"></a></p>
<h3><strong>3. Python implementation</strong></h3>
<p>We use the MNIST dataset for a python experiment on Boltzmann machines. The dataset consists of 70000 images of handwritten digits, from 0 to 9. Each image contains <span class="math">\(28\times 28=784\)</span> pixels ranging from 0 to 255. If we work with normalized pixels, then we can interpret that value as the probability of being white or black. We can then generate a set of binary states by drawing zeros or ones according to each pixel probability.</p>
<p>Once the model is trained we can generate samples of visible states using Gibbs sampling. First we take a random set of visible states <span class="math">\(v^0\)</span>, then we use <span class="math">\(P(h|v^0)\)</span> to generate a sample of hidden states <span class="math">\(h^0\)</span>. Given this hidden state we can generate a new sample of visible states <span class="math">\(v^1\)</span> using <span class="math">\(P(v|h^0)\)</span>. </p>
<ul>
<li>RBM class</li>
</ul>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RBM</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">vis_dim</span><span class="p">,</span><span class="n">hidden_dim</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vis_dim</span><span class="o">=</span><span class="n">vis_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.001</span><span class="p">,(</span><span class="n">vis_dim</span><span class="p">,</span><span class="n">hidden_dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias_vis</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.001</span><span class="p">,</span><span class="n">vis_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias_hid</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.001</span><span class="p">,</span><span class="n">hidden_dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">prob_h_v</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">vis_vec</span><span class="p">):</span>

        <span class="n">probs</span><span class="o">=</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_hid</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">vis_vec</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">))</span>

        <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="n">probs</span>

    <span class="k">def</span> <span class="nf">prob_v_h</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">hid_vec</span><span class="p">):</span>

        <span class="n">probs</span><span class="o">=</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_vis</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hid_vec</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>

        <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="n">probs</span>

    <span class="k">def</span> <span class="nf">Pv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">vis_vec</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">()</span>
        <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__phi</span><span class="p">(</span><span class="n">vis_vec</span><span class="p">)</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">Z_</span>

        <span class="k">return</span> <span class="n">p</span>

    <span class="k">def</span> <span class="nf">__phi</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">vis_vec</span><span class="p">):</span>

        <span class="n">p</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">vis_vec</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_vis</span><span class="p">))</span>
        <span class="n">t</span><span class="o">=</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_hid</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">vis_vec</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">))</span>
        <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">p</span>

    <span class="k">def</span> <span class="nf">pseudoLL</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">):</span>

        <span class="n">phis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__phi</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">pseudo</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">temp</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="c1">#flip</span>
            <span class="n">temp</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">temp</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">Z</span><span class="o">=</span><span class="n">phis</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">__phi</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
            <span class="n">pseudo</span><span class="o">+=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">phis</span><span class="o">/</span><span class="n">Z</span><span class="p">)</span>
            <span class="c1">#flip again</span>
            <span class="n">temp</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">temp</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="o">-</span><span class="n">pseudo</span>

    <span class="k">def</span> <span class="nf">Z</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
        <span class="n">vis_rand</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">vis_dim</span><span class="p">)</span>
        <span class="n">vis</span><span class="o">=</span><span class="p">(</span><span class="n">vis_rand</span><span class="o">&lt;=</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Z_</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__phi</span><span class="p">(</span><span class="n">vis</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">gibbs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">vec</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
            <span class="n">prob_hid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prob_h_v</span><span class="p">(</span><span class="n">vec</span><span class="p">)</span>
            <span class="n">rand</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">vec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span>
            <span class="n">hid_vec</span><span class="o">=</span><span class="p">(</span><span class="n">rand</span><span class="o">&lt;=</span><span class="n">prob_hid</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>
            <span class="n">prob_vis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prob_v_h</span><span class="p">(</span><span class="n">hid_vec</span><span class="p">)</span>
            <span class="n">rand</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">vec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">vis_dim</span><span class="p">)</span>
            <span class="n">vec</span><span class="o">=</span><span class="p">(</span><span class="n">rand</span><span class="o">&lt;=</span><span class="n">prob_vis</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">vec</span>
</pre></div>


<ul>
<li>Log-Loss class</li>
</ul>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LogLoss</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">=</span><span class="n">model</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">):</span>
        <span class="n">pseudo</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">pseudoLL</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">pseudo</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>       
</pre></div>


<ul>
<li>Optimizer class</li>
</ul>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Optimizer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">model</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">=</span><span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="o">=</span><span class="n">lr</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">vis_batch</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

        <span class="n">hid_prob</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">prob_h_v</span><span class="p">(</span><span class="n">vis_batch</span><span class="p">)</span>
        <span class="n">hid_rand</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">vis_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span>
        <span class="n">hid_data</span><span class="o">=</span><span class="p">(</span><span class="n">hid_rand</span><span class="o">&lt;=</span><span class="n">hid_prob</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>

        <span class="n">vis_model</span><span class="o">=</span><span class="n">vis_batch</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
            <span class="n">hid_prob</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">prob_h_v</span><span class="p">(</span><span class="n">vis_model</span><span class="p">)</span>
            <span class="n">hid_rand</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">vis_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span>
            <span class="n">hid_model</span><span class="o">=</span><span class="p">(</span><span class="n">hid_rand</span><span class="o">&lt;=</span><span class="n">hid_prob</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>

            <span class="n">vis_prob</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">prob_v_h</span><span class="p">(</span><span class="n">hid_model</span><span class="p">)</span>
            <span class="n">vis_rand</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">vis_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vis_dim</span><span class="p">)</span>
            <span class="n">vis_model</span><span class="o">=</span><span class="p">(</span><span class="n">vis_rand</span><span class="o">&lt;=</span><span class="n">vis_prob</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>

        <span class="n">hv_data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">vis_batch</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">hid_data</span><span class="p">)</span>
        <span class="n">hv_data</span><span class="o">=</span><span class="n">hv_data</span><span class="o">/</span><span class="n">vis_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">hv_model</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">vis_model</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">hid_model</span><span class="p">)</span>
        <span class="n">hv_model</span><span class="o">=</span><span class="n">hv_model</span><span class="o">/</span><span class="n">vis_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">weight</span><span class="o">-=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="o">*</span><span class="p">(</span><span class="n">hv_data</span><span class="o">-</span><span class="n">hv_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">bias_vis</span><span class="o">-=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="o">*</span><span class="p">(</span><span class="n">vis_batch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">-</span><span class="n">vis_model</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">bias_hid</span><span class="o">-=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="o">*</span><span class="p">(</span><span class="n">hid_data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">-</span><span class="n">hid_model</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</pre></div>


<ul>
<li>Data preparation</li>
</ul>
<div class="highlight"><pre><span></span><span class="c1">#Make visible units out of pixels</span>
<span class="k">class</span> <span class="nc">VisibleGen</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">,</span><span class="n">norm</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">==</span><span class="mi">3</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">=</span><span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="o">=</span><span class="n">norm</span>

    <span class="k">def</span> <span class="nf">make_visible</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">norm</span>
        <span class="n">rand</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">visible</span><span class="o">=</span><span class="p">(</span><span class="n">rand</span><span class="o">&lt;=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">visible</span>

<span class="c1"># Data-loader creates mini-batches of data</span>
<span class="k">class</span> <span class="nc">DataLoader</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="o">=</span><span class="n">batch_size</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">L</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">%</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="o">+</span><span class="mi">1</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
            <span class="n">j</span><span class="o">=</span><span class="n">i</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span>
            <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">j</span><span class="p">:</span><span class="n">j</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">]</span>
</pre></div>


<ul>
<li>Training function</li>
</ul>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">data_loader</span><span class="p">,</span><span class="n">optimizer</span><span class="p">,</span><span class="n">loss</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">total_loss</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
            <span class="n">L</span><span class="o">=</span><span class="n">loss</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">total_loss</span><span class="o">+=</span><span class="n">L</span>
        <span class="n">total_loss</span><span class="o">=</span><span class="n">total_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;epoch: &#39;</span><span class="p">,</span><span class="n">epoch</span><span class="p">,</span><span class="s1">&#39;, Loss: &#39;</span><span class="p">,</span><span class="n">total_loss</span><span class="p">)</span>
</pre></div>


<p>We generate visible units from a sample of the MNIST data.</p>
<div class="highlight"><pre><span></span><span class="n">idx</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">mnist_28x28</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sample</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span><span class="mi">2000</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">sample_img</span><span class="o">=</span><span class="n">mnist_28x28</span><span class="p">[</span><span class="n">sample</span><span class="p">]</span>

<span class="n">vis_28x28</span><span class="o">=</span><span class="n">VisibleGen</span><span class="p">(</span><span class="n">sample_img</span><span class="p">,</span><span class="mi">255</span><span class="p">)</span>
<span class="n">vis_28x28_data</span><span class="o">=</span><span class="n">vis_28x28</span><span class="o">.</span><span class="n">make_visible</span><span class="p">()</span>
<span class="n">vis_28x28_loader</span><span class="o">=</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">vis_28x28_data</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
</pre></div>


<p>We create a RBM with 100 hidden units and use a learning rate=0.01.</p>
<div class="highlight"><pre><span></span><span class="n">rbm_28x28</span><span class="o">=</span><span class="n">RBM</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">loss</span><span class="o">=</span><span class="n">LogLoss</span><span class="p">(</span><span class="n">rbm_28x28</span><span class="p">)</span>
<span class="n">opt</span><span class="o">=</span><span class="n">Optimizer</span><span class="p">(</span><span class="n">rbm_28x28</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>


<p>The first 10 epochs of training
<img alt="" height="300" src="/images/rbm_losses.png" style="display: block; margin: 0 auto" width="300"> 
we can see that the pseudo-loss decreases steadily.</p>
<p>Once the model is trained we can generate samples using a Gibbs sampler that is built in the RBM class.
After 10 epochs:</p>
<p><img alt="" height="600" src="/images/rbm_train_10.png" style="display: block; margin: 0 auto" width="600"> </p>
<p>After 20 epochs:</p>
<p><img alt="" height="600" src="/images/rbm_train_20.png" style="display: block; margin: 0 auto" width="600"> </p>
<p>And finally after 40 epochs:</p>
<p><img alt="" height="600" src="/images/rbm_train_40.png" style="display: block; margin: 0 auto" width="600"> </p>
<p>We see that with longer training the generated samples show more differentiation.</p>
<h3><strong>References</strong></h3>
<p><br/></p>
<p>[1] <em>A Practical Guide to Training Restricted Boltzmann Machines</em>, G. Hinton, (2010)</p>
<p>[2] <em>An Efficient Learning Procedure for Deep Boltzmann Machines</em>, G. Hinton, R. Salakhutdinov (2012)</p>
<p>[3] <em>Deep Learning</em>, A. Courville, I. Goodfellow, Y. Bengio, (book)</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script></div>
	<hr>
	<h2>Comments</h2>
</div>
		</div>
	</div> 	<!-- <hr> -->
</div> <!-- /container -->
<footer class="aw-footer bg-danger">
	<div class="container"> <!-- footer -->
		<div class="row">
			<div class="col-md-10 col-md-offset-1">
				<div class="row">
					<div class="col-md-3">
						<h4>Navigation</h4>
						<ul class="list-unstyled my-list-style">
							<li><a href="">Data Science and Machine Learning</a></li>
							<li><a href="/pages/about-me.html"><i class="fa fa-About me "></i> About me</a></li>
							<li><a href="/feeds/all.atom.xml" type="application/atom+xml"><i class="fa fa-rss "></i> atom</a></li>
						</ul>
					</div>
					<div class="col-md-3">
						<h4>Author</h4>
						<ul class="list-unstyled my-list-style">
							<li><a href="https://www.linkedin.com/in/joaomvg/">LinkedIn</a></li>
							<li><a href="https://github.com/joaomvg">GitHub</a></li>
						</ul>
					</div>
					<div class="col-md-3">
						<h4>Categories</h4>
						<ul class="list-unstyled my-list-style">
							<li><a href="/category/data-science.html">Data Science (1)</a></li>
							<li><a href="/category/machine-learning.html">Machine Learning (21)</a></li>
							<li><a href="/category/python.html">Python (1)</a></li>
							<li><a href="/category/statistics.html">Statistics (2)</a></li>
						</ul>
					</div>
					<div class="col-md-3">
						<h4>Links</h4>
						<ul class="list-unstyled my-list-style">
							<li><a href="archives.html">Archives</a></li>
							<li><a href="tags.html">Tags</a></li>
						</ul>
					</div>
				</div>
			</div>
		</div>
	</div>
</footer>
<div class="container">
	<div class="row">
		<div class="col-md-12 text-center center-block aw-bottom">
			<p>&copy; Joao Gomes 2016</p>
			<p>Powered by Pelican</p>
		</div>
	</div>
</div>
<!-- JavaScript -->
<script src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
<script type="text/javascript">
jQuery(document).ready(function($) {
	$("div.collapseheader").click(function () {
		$header = $(this).children("span").first();
		$codearea = $(this).children(".input_area");
		$codearea.slideToggle(500, function () {
			$header.text(function () {
				return $codearea.is(":visible") ? "Collapse Code" : "Expand Code";
			});
		});
	});
});
</script>
</body>
</html>