<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>"AdaBoost" â€” Data Science and Machine Learning</title>
	<meta name="description" content="Title: "AdaBoost"; Date: 2020-09-27; Author: Joao Gomes">
	<meta name="author" content="Joao Gomes">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
	<!--[if lt IE 9]>
		<script src="/theme/html5.js"></script>
		<![endif]-->
	<link href="/theme/css/ipython.css" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/bootswatch/3.2.0/simplex/bootstrap.min.css" rel="stylesheet">
	<link href="/theme/css/local.css" rel="stylesheet">
	<link href="/theme/css/pygments.css" rel="stylesheet">
</head>
<body>
<div class="container">
	<div class="page-header">
		<h1><a href="/">Data Science and Machine Learning</a>
			<br>	</div>
	<div class="row">
		<div class="col-md-8 col-md-offset-2">
<div class="article" itemscope itemtype="http://schema.org/BlogPosting">
	<div class="text-center article-header">
		<h1 itemprop="name headline" class="article-title">"AdaBoost"</h1>
		<span itemprop="author" itemscope itemtype="http://schema.org/Person">
			<h4 itemprop="name">Joao Gomes</h4>
		</span>
		<time datetime="2020-09-27T00:00:00+02:00" itemprop="datePublished">Sun 27 September 2020</time>
	</div>
	<div>
		Category:
		<span itemprop="articleSection">
			<a href="/category/machine-learning.html" rel="category">Machine Learning</a>
		</span>
	</div>
 
	<div>
		Tags:
		<span itemprop="keywords">
			<a href="/tag/data-science.html" rel="tag">data science</a>
		</span>
	</div>
	<div itemprop="articleBody" class="article-body"><ol>
<li><a href="#def1">Boosting</a></li>
<li><a href="#decision">Decision Boundary</a></li>
<li><a href="#python">Python implementation</a></li>
</ol>
<p><a name="def1"></a></p>
<h3><strong>1. Boosting</strong></h3>
<p>Problems in machine learning often consist of a very large number of features, which can lead to difficulties in training and generalization properties. Boosting is a type of algorithm that allows to focus on the most relevant features in an iterative manner, selecting only those features that improve the model.</p>
<p>Consider a binary classification model with classes <span class="math">\(\{-1,1\}\)</span>. In adaboosting or adaptive boosting, we fit a series of weak-learners in an iterative way. A weak-learner is an algorithm that performs only slightly better than chance. An example, can be a decision tree with small depth. At each step in adaboosting, a new weak learner is fitted to the data but using different weights so that the algorithm focus on the datapoints it finds harder to classify. </p>
<p>After the mth-step the classifier will have the form
</p>
<div class="math">$$C_{m}(x)=\alpha_1h_1(x)+\ldots+\alpha_{m}h_{m}(x)$$</div>
<p>
In each step we minimize the exponential loss function by choosing <span class="math">\(\alpha\)</span>. At the mth step this loss function is
</p>
<div class="math">$$\frac{1}{N}\sum_{i=1}^N e^{-y_i C_m(x_i)}=\frac{1}{N}\sum_{i=1}^N e^{-y_i C_{m-1}(x_i)-y_ih_m(x_i)\alpha_m}=\sum_i \omega_i e^{-y_ih_m(x_i)\alpha_m}$$</div>
<p>
where <span class="math">\(\omega_i=e^{-y_iC_{m-1}(x_i)}/N\)</span> is a weight, and we fit the mth weak learner <span class="math">\(h_m(x)\)</span> on the data weighted by <span class="math">\(\omega_i\)</span>. Differentiating with respect to <span class="math">\(\alpha_m\)</span> and setting to zero we obtain
</p>
<div class="math">$$\sum_i\omega_i y_ih_m(x_i)e^{-y_ih_m(x_i)\alpha_m}=0\iff \sum_{y_i=h_m(x_i)}\omega_ie^{-\alpha_m}-\sum_{y_i\neq h_m(x_i)}\omega_ie^{\alpha_m}=0\iff \frac{\sum_{y_i=h_m(x_i)}\omega_i}{\sum_{y_i\neq h_m(x_i)}\omega_i}=e^{2\alpha_m}$$</div>
<p>
Normalizing the weights such that <span class="math">\(\sum_i\omega_i=1\)</span>, we calculate the parameter <span class="math">\(\alpha_m\)</span> as
</p>
<div class="math">$$\alpha_m=\frac{1}{2}\ln\Big(\frac{1-\sum_{y_i\neq h_m(x_i)}\omega_i}{\sum_{y_i\neq h_m(x_i)}\omega_i}\Big)=\frac{1}{2}\ln\Big(\frac{1-\epsilon_m}{\epsilon_m}\Big)$$</div>
<p>
where <span class="math">\(\epsilon_m\)</span> is the weighted error
</p>
<div class="math">$$\epsilon_m=\sum_{y_i\neq h_m(x_i)}\omega_i$$</div>
<p>
For <span class="math">\(m=1\)</span>, the first step, the weights are <span class="math">\(\omega_i=1/N\)</span>.</p>
<p>In summary the algorithm consists:</p>
<div class="highlight"><pre><span></span><span class="n">w</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">N</span> <span class="c1"># weight initialization</span>
<span class="n">learners</span><span class="o">=</span><span class="p">[]</span> <span class="c1"># list of weak learners</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
    <span class="n">Weak_Learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
    <span class="n">error</span><span class="o">=</span><span class="n">Weak_Learner</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span> <span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">error</span><span class="o">/</span><span class="n">error</span><span class="p">)</span>
    <span class="n">learners</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">alpha</span><span class="o">*</span><span class="n">Weak_Learner</span><span class="p">)</span>
    <span class="n">w</span><span class="o">=</span><span class="n">Weight</span><span class="o">.</span><span class="n">recalculate</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>

<span class="c1">#predictor function</span>
<span class="k">def</span> <span class="nf">C</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">prediction</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">wl</span> <span class="ow">in</span> <span class="n">learners</span><span class="p">:</span>
        <span class="n">prediction</span><span class="o">+=</span><span class="n">wl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sign</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
</pre></div>


<p><a name="decision"></a></p>
<h3><strong>2. Decision Boundary</strong></h3>
<p>We fit an Adaboost classifier to a dataset consisting of two sets of points, red and blue, normally distributed. Below is the Adaboost prediction after six steps.
<img alt="" height="400" src="/images/adaboost50.png" style="display: block; margin: 0 auto" width="400"> 
And below we present the prediction of its six estimators in the order of training, from left to right</p>
<p><img alt="" height="1000" src="/images/adaboost5.png" style="display: block; margin: 0 auto" width="1300"> </p>
<p>At each step we superimpose the prediction from the previous estimatores:
<img alt="" height="1000" src="/images/adaboost_seq.png" style="display: block; margin: 0 auto" width="1300"> </p>
<p>One can see that at each step the alogrithm tries to "fix" the misclassified points.</p>
<p>With more estimators, the decision boundary becomes more complex
<img alt="" height="400" src="/images/adaboost_.png" style="display: block; margin: 0 auto" width="400"> </p>
<p><a name="python"></a></p>
<h3><strong>3. Python Implementation</strong></h3>
<p>We build a class node that stores the weak learners. The attribute "next"  points to the next weak-learner in the series.</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">node</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">tree</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="o">=</span><span class="n">tree</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">next</span><span class="o">=</span><span class="kc">None</span>

    <span class="k">def</span> <span class="nf">insert</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">alpha</span><span class="p">,</span><span class="n">tree</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">next</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">next</span><span class="o">=</span><span class="n">node</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">tree</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">next</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">tree</span><span class="p">)</span>
</pre></div>


<p>The class Adaboost contains fit and predict methods.</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">AdaBoost</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">T</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="o">=</span><span class="n">T</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="o">=</span><span class="n">node</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">tree</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">ypred</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">sample_weight</span><span class="p">):</span>
        <span class="n">error</span><span class="o">=</span><span class="mi">1</span><span class="o">-</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">ypred</span><span class="p">,</span><span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">error</span><span class="o">==</span><span class="mf">1.0</span><span class="p">:</span>
            <span class="k">return</span> <span class="s1">&#39;stop&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">error</span><span class="p">)</span><span class="o">/</span><span class="n">error</span><span class="p">)</span>
            <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">y</span><span class="o">*</span><span class="n">ypred</span><span class="o">*</span><span class="n">alpha</span><span class="p">)</span>
            <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="o">/</span><span class="n">sample_weight</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="k">return</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">sample_weight</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>

        <span class="n">sample_weight</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
        <span class="n">ypred</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">alpha</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">ypred</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">sample_weight</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">):</span>
            <span class="n">tree</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
            <span class="n">ypred</span><span class="o">=</span><span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">alpha</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">ypred</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">sample_weight</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">tree</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">read</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">node</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">ypred</span><span class="o">=</span><span class="n">node</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">ypred</span><span class="o">=</span><span class="n">node</span><span class="o">.</span><span class="n">alpha</span><span class="o">*</span><span class="n">ypred</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">next</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ypred</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ypred</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">next</span><span class="p">,</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">ypred</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">,</span><span class="n">x</span><span class="p">)</span>
        <span class="n">ypred</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">ypred</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ypred</span>  
</pre></div>


<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script></div>
	<hr>
	<h2>Comments</h2>
</div>
		</div>
	</div> 	<!-- <hr> -->
</div> <!-- /container -->
<footer class="aw-footer bg-danger">
	<div class="container"> <!-- footer -->
		<div class="row">
			<div class="col-md-10 col-md-offset-1">
				<div class="row">
					<div class="col-md-3">
						<h4>Navigation</h4>
						<ul class="list-unstyled my-list-style">
							<li><a href="">Data Science and Machine Learning</a></li>
							<li><a href="/pages/about-me.html"><i class="fa fa-About me "></i> About me</a></li>
							<li><a href="/feeds/all.atom.xml" type="application/atom+xml"><i class="fa fa-rss "></i> atom</a></li>
						</ul>
					</div>
					<div class="col-md-3">
						<h4>Author</h4>
						<ul class="list-unstyled my-list-style">
							<li><a href="https://www.linkedin.com/in/joaomvg/">LinkedIn</a></li>
							<li><a href="https://github.com/joaomvg">GitHub</a></li>
						</ul>
					</div>
					<div class="col-md-3">
						<h4>Categories</h4>
						<ul class="list-unstyled my-list-style">
							<li><a href="/category/data-science.html">Data Science (1)</a></li>
							<li><a href="/category/machine-learning.html">Machine Learning (21)</a></li>
							<li><a href="/category/python.html">Python (1)</a></li>
							<li><a href="/category/statistics.html">Statistics (2)</a></li>
						</ul>
					</div>
					<div class="col-md-3">
						<h4>Links</h4>
						<ul class="list-unstyled my-list-style">
							<li><a href="archives.html">Archives</a></li>
							<li><a href="tags.html">Tags</a></li>
						</ul>
					</div>
				</div>
			</div>
		</div>
	</div>
</footer>
<div class="container">
	<div class="row">
		<div class="col-md-12 text-center center-block aw-bottom">
			<p>&copy; Joao Gomes 2016</p>
			<p>Powered by Pelican</p>
		</div>
	</div>
</div>
<!-- JavaScript -->
<script src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
<script type="text/javascript">
jQuery(document).ready(function($) {
	$("div.collapseheader").click(function () {
		$header = $(this).children("span").first();
		$codearea = $(this).children(".input_area");
		$codearea.slideToggle(500, function () {
			$header.text(function () {
				return $codearea.is(":visible") ? "Collapse Code" : "Expand Code";
			});
		});
	});
});
</script>
</body>
</html>